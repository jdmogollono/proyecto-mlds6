{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a9cc180",
   "metadata": {
    "id": "4a9cc180"
   },
   "source": [
    "### **Carga o Adquisición de Datos**\n",
    "---\n",
    "Tiempo estimado ~ 6 horas\n",
    "\n",
    "Espacio Requerido ~ 10GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b580368",
   "metadata": {
    "id": "1b580368"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import base64\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import multiprocessing as mp\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "BTZUT6w_yAht",
   "metadata": {
    "id": "BTZUT6w_yAht"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace: /home/jovyan/work/proyecto-mlds6\n",
      "Data folder: /home/jovyan/work/proyecto-mlds6/data\n"
     ]
    }
   ],
   "source": [
    "# Navegar hasta la raíz del proyecto \n",
    "WORKSPACE = os.path.abspath(os.path.join(os.getcwd(), '../../'))\n",
    "\n",
    "# Definir la ruta de la carpeta de datos\n",
    "DATA_FOLDER = os.path.join(WORKSPACE, 'data')\n",
    "\n",
    "print(\"Workspace:\", WORKSPACE)\n",
    "print(\"Data folder:\", DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "FbBt9acjFnL-",
   "metadata": {
    "id": "FbBt9acjFnL-"
   },
   "outputs": [],
   "source": [
    "def get_station_data(station_codes, start_date, end_date, id_parametro, etiqueta, group_size=20):\n",
    "    \"\"\"\n",
    "    Obtiene datos de estaciones del servidor IDEAM.\n",
    "\n",
    "    Entradas:\n",
    "    - station_codes: Lista de códigos de estaciones\n",
    "    - start_date: Fecha de inicio\n",
    "    - end_date: Fecha de fin\n",
    "    - id_parametro: ID del parámetro a obtener\n",
    "    - etiqueta: Etiqueta del parámetro\n",
    "    - group_size: Tamaño del grupo de estaciones para procesar\n",
    "\n",
    "    Salida:\n",
    "    - None (guarda los archivos en DATA_FOLDER)\n",
    "    \"\"\"\n",
    "    url = \"http://dhime.ideam.gov.co/server/rest/services/AtencionCiudadano/DescargarArchivo/GPServer/DescargarArchivo/submitJob\"\n",
    "    groups = [station_codes[i:i + group_size] for i in range(0, len(station_codes), group_size)]\n",
    "\n",
    "    empty_groups = 0\n",
    "    overtime_groups = 0\n",
    "    total_groups = len(groups)\n",
    "\n",
    "    with tqdm(total=total_groups, desc=f\"PROCESANDO {etiqueta} ({id_parametro})\", unit=\"grupo\") as pbar:\n",
    "        for group in groups:\n",
    "            filter_stations = \"~or~\".join([f\"(IdParametro~eq~'{id_parametro}'~and~Etiqueta~eq~'{etiqueta}'~and~IdEstacion~eq~'{code}')\" for code in group])\n",
    "            params = {\n",
    "                \"Filtro\": f\"sort=&filter=({filter_stations})&group=&fechaInicio={start_date}T05%3A00%3A00.000Z&fechaFin={end_date}T05%3A00%3A00.000Z&mostrarGrado=true&mostrarCalificador=true&mostrarNivelAprobacion=true\",\n",
    "                \"Items\": json.dumps([{\"IdParametro\": id_parametro, \"Etiqueta\": etiqueta, \"EsEjeY1\": False, \"EsEjeY2\": False, \"EsTipoLinea\": False, \"EsTipoBarra\": False, \"TipoSerie\": \"Estandard\", \"Calculo\": \"\"}] * len(group)),\n",
    "                \"f\": \"pjson\"\n",
    "            }\n",
    "\n",
    "            response = requests.post(url, data=params)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                job_id = response.json()['jobId']\n",
    "                zip_url = f\"http://dhime.ideam.gov.co/server/rest/services/AtencionCiudadano/DescargarArchivo/GPServer/DescargarArchivo/jobs/{job_id}/results/Archivo?f=pjson\"\n",
    "\n",
    "                start_time = time.time()\n",
    "                saved_data = False\n",
    "                while True:\n",
    "                    zip_response = requests.get(zip_url)\n",
    "                    if zip_response.status_code == 200 and 'value' in zip_response.json():\n",
    "                        base64_string = zip_response.json()['value']\n",
    "                        padding = 4 - (len(base64_string) % 4)\n",
    "                        if padding:\n",
    "                            base64_string += '=' * padding\n",
    "\n",
    "                        try:\n",
    "                            decoded_bytes = base64.b64decode(base64_string)\n",
    "                            with zipfile.ZipFile(io.BytesIO(decoded_bytes)) as zip_file:\n",
    "                                for filename in zip_file.namelist():\n",
    "                                    if filename.endswith('.csv'):\n",
    "                                        with zip_file.open(filename) as f:\n",
    "                                            csv_data = f.read()\n",
    "                                        os.makedirs(f'{DATA_FOLDER}/variables/', exist_ok=True)\n",
    "                                        with open(f'{DATA_FOLDER}/variables/{etiqueta}.csv', 'ab') as file:\n",
    "                                            file.write(csv_data)\n",
    "                                        saved_data = True\n",
    "                            break\n",
    "                        except Exception as e:\n",
    "                            if not saved_data:\n",
    "                                empty_groups += 1\n",
    "                            break\n",
    "                    elif time.time() - start_time > 120:\n",
    "                        if not saved_data:\n",
    "                            overtime_groups += 1\n",
    "                            print(f\"{etiqueta} : {group}\")\n",
    "                        break\n",
    "                    else:\n",
    "                        time.sleep(1)\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    print(f\"Número de grupos sin datos: {empty_groups}/{total_groups}\")\n",
    "    print(f\"Número de grupos fuera del límite de espera: {overtime_groups}/{total_groups}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f81209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_estacion(codigo_estacion, variables_dataframes, fecha_inicio, fecha_fin, output_folder):\n",
    "    \"\"\"\n",
    "    Procesa una estación individual y crea su archivo CSV con todas las variables.\n",
    "    \n",
    "    Args:\n",
    "        codigo_estacion (str): Código de la estación a procesar\n",
    "        variables_dataframes (dict): Diccionario con los DataFrames de variables\n",
    "        fecha_inicio (str): Fecha de inicio del período a procesar\n",
    "        fecha_fin (str): Fecha fin del período a procesar\n",
    "        output_folder (str): Carpeta donde se guardarán los archivos CSV\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Crear un DataFrame vacío con el rango de fechas completo\n",
    "        fecha_idx = pd.date_range(start=fecha_inicio, end=fecha_fin, freq='D')\n",
    "        df_estacion = pd.DataFrame(index=fecha_idx)\n",
    "        df_estacion.index.name = 'Fecha'\n",
    "        \n",
    "        # Para cada variable, obtener los valores correspondientes a la estación\n",
    "        for nombre_var, df_var in variables_dataframes.items():\n",
    "            # Filtrar datos para esta estación\n",
    "            datos_var = df_var[df_var['CodigoEstacion'] == codigo_estacion].copy()\n",
    "            \n",
    "            # Convertir los datos a serie temporal con la fecha como índice\n",
    "            if not datos_var.empty:\n",
    "                serie_temporal = pd.Series(\n",
    "                    datos_var[nombre_var].values,\n",
    "                    index=datos_var['Fecha'],\n",
    "                    name=nombre_var\n",
    "                )\n",
    "            else:\n",
    "                # Si no hay datos para esta variable, crear una serie vacía con NaN\n",
    "                serie_temporal = pd.Series(\n",
    "                    np.nan,\n",
    "                    index=fecha_idx,\n",
    "                    name=nombre_var\n",
    "                )\n",
    "            \n",
    "            # Unir con el DataFrame principal\n",
    "            # Esto automáticamente alineará las fechas y pondrá NaN donde no haya datos\n",
    "            df_estacion = df_estacion.join(serie_temporal)\n",
    "        \n",
    "        # Eliminar las filas donde todas las variables son NaN\n",
    "        df_estacion = df_estacion.dropna(how='all')\n",
    "\n",
    "        # Verificar si tenemos al menos una variable con datos\n",
    "        if len(df_estacion) > 0:\n",
    "            # Guardar el DataFrame como CSV\n",
    "            output_path = os.path.join(output_folder, f'{codigo_estacion}.csv')\n",
    "            df_estacion.to_csv(output_path, date_format='%Y-%m-%d')\n",
    "            return f\"Procesada estación {codigo_estacion}\"\n",
    "        else:\n",
    "            return f\"Estación {codigo_estacion} no tiene datos para ninguna variable\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error procesando estación {codigo_estacion}: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf908fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_estaciones_paralelo(catalogo_estaciones_activas, variables_dataframes, \n",
    "                                 fecha_inicio, fecha_fin,\n",
    "                                 output_folder, chunk_size=500):\n",
    "    \"\"\"\n",
    "    Procesa todas las estaciones en paralelo usando todos los núcleos disponibles,\n",
    "    procesando en lotes de 100 estaciones y mostrando el progreso con una barra de progreso.\n",
    "    \n",
    "    Args:\n",
    "        catalogo_estaciones_activas (pd.DataFrame): DataFrame con las estaciones activas.\n",
    "        variables_dataframes (dict): Diccionario con los DataFrames de variables.\n",
    "        fecha_inicio (str): Fecha de inicio del período a procesar.\n",
    "        fecha_fin (str): Fecha fin del período a procesar.\n",
    "        output_folder (str): Carpeta donde se guardarán los archivos CSV.\n",
    "    \"\"\"\n",
    "    # Crear la carpeta de salida si no existe\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Obtener lista de códigos de estaciones\n",
    "    codigos_estaciones = catalogo_estaciones_activas['CODIGO'].unique()\n",
    "    \n",
    "    # Dividir las estaciones en lotes\n",
    "    lotes_estaciones = [codigos_estaciones[i:i + chunk_size] for i in range(0, len(codigos_estaciones), chunk_size)]\n",
    "    \n",
    "    # Configurar el procesamiento en paralelo\n",
    "    num_cores = mp.cpu_count()\n",
    "    print(f\"Utilizando {num_cores} núcleos para el procesamiento\")\n",
    "    print(f\"Procesando {len(codigos_estaciones)} estaciones en {len(lotes_estaciones)} lotes de {chunk_size} estaciones\")\n",
    "    print(f\"Variables disponibles: {list(variables_dataframes.keys())}\")\n",
    "    \n",
    "    # Crear función parcial con los argumentos comunes\n",
    "    func = partial(procesar_estacion, \n",
    "                   variables_dataframes=variables_dataframes,\n",
    "                   fecha_inicio=fecha_inicio,\n",
    "                   fecha_fin=fecha_fin,\n",
    "                   output_folder=output_folder)\n",
    "    \n",
    "    # Inicializar los contadores globales para el resumen final\n",
    "    estaciones_con_datos_global = 0\n",
    "    estaciones_sin_datos_global = 0\n",
    "    estaciones_con_error_global = 0\n",
    "    \n",
    "    # Inicializar barra de progreso\n",
    "    with tqdm(total=len(codigos_estaciones)) as pbar:\n",
    "        # Procesar los lotes en paralelo\n",
    "        for lote in lotes_estaciones:\n",
    "            # Crear pool de procesos\n",
    "            with mp.Pool(num_cores) as pool:\n",
    "                resultados = pool.map(func, lote)\n",
    "            \n",
    "            # Actualizar la barra de progreso\n",
    "            pbar.update(len(lote))\n",
    "            \n",
    "            # Contadores parciales\n",
    "            estaciones_con_datos = 0\n",
    "            estaciones_sin_datos = 0\n",
    "            estaciones_con_error = 0\n",
    "            \n",
    "            # Mostrar resultados parciales y actualizar contadores globales\n",
    "            for resultado in resultados:\n",
    "                if \"no tiene datos\" in resultado:\n",
    "                    estaciones_sin_datos += 1\n",
    "                    estaciones_sin_datos_global += 1\n",
    "                elif \"Error\" in resultado:\n",
    "                    estaciones_con_error += 1\n",
    "                    estaciones_con_error_global += 1\n",
    "                else:\n",
    "                    estaciones_con_datos += 1\n",
    "                    estaciones_con_datos_global += 1\n",
    "\n",
    "    # Mostrar resumen final\n",
    "    print(\"\\nResumen final del procesamiento de todas las estaciones:\")\n",
    "    print(f\"- Estaciones procesadas con éxito: {estaciones_con_datos_global}\")\n",
    "    print(f\"- Estaciones sin datos: {estaciones_sin_datos_global}\")\n",
    "    print(f\"- Estaciones con errores: {estaciones_con_error_global}\")\n",
    "    print(f\"\\nLos archivos CSV se encuentran en: {output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3d6de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidar_csv(data_path, output_file):\n",
    "    \"\"\"\n",
    "    Lee todos los archivos CSV en una carpeta, los une y agrega una nueva columna con el nombre del archivo.\n",
    "    \n",
    "    Args:\n",
    "        data_path (str): Ruta de la carpeta que contiene los archivos CSV.\n",
    "        output_file (str): Nombre del archivo CSV de salida con los datos consolidados.\n",
    "    \"\"\"\n",
    "    # Obtener la lista de archivos CSV en la carpeta\n",
    "    archivos_csv = [f for f in os.listdir(data_path) if f.endswith('.csv')]\n",
    "    \n",
    "    # Lista para almacenar los DataFrames\n",
    "    dataframes = []\n",
    "    \n",
    "    # Iterar sobre cada archivo CSV\n",
    "    for archivo in archivos_csv:\n",
    "        archivo_path = os.path.join(data_path, archivo)\n",
    "        \n",
    "        # Leer el archivo CSV en un DataFrame\n",
    "        df = pd.read_csv(archivo_path)\n",
    "        \n",
    "        # Agregar una nueva columna con el nombre del archivo \n",
    "        df.insert(0, 'CodigoEstacion', os.path.splitext(archivo)[0])\n",
    "        \n",
    "        # Agregar el DataFrame a la lista\n",
    "        dataframes.append(df)\n",
    "    \n",
    "    # Concatenar todos los DataFrames en uno solo\n",
    "    df_consolidado = pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "    # Guardar el DataFrame consolidado en un nuevo archivo CSV\n",
    "    df_consolidado.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Archivo CSV consolidado guardado en: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hWIseJvKlq_-",
   "metadata": {
    "id": "hWIseJvKlq_-"
   },
   "outputs": [],
   "source": [
    "def download_cne():\n",
    "    url = \"https://bart.ideam.gov.co/cneideam/CNE_IDEAM.xls\"\n",
    "    os.makedirs(DATA_FOLDER, exist_ok=True)\n",
    "    file_name = os.path.basename(url)\n",
    "    file_path = os.path.join(DATA_FOLDER, file_name)\n",
    "    response = requests.get(url, verify=False)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        with open(file_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "hHLdbK1el2cs",
   "metadata": {
    "id": "hHLdbK1el2cs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de estaciones activas: 2624\n"
     ]
    }
   ],
   "source": [
    "# Leer el catálogo nacional de estaciones del IDEAM\n",
    "download_cne()\n",
    "catalogo_estaciones = pd.read_excel(os.path.join(DATA_FOLDER, 'CNE_IDEAM.xls'))\n",
    "\n",
    "# Filtrar estacioness\n",
    "catalogo_estaciones_activas = catalogo_estaciones[catalogo_estaciones[\"ESTADO\"] != \"Suspendida\"]\n",
    "print(f'Número de estaciones activas: {len(catalogo_estaciones_activas)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_7O2_JDEi_9G",
   "metadata": {
    "id": "_7O2_JDEi_9G"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PROCESANDO NV_MEDIA_D (NIVEL): 100%|██████████| 132/132 [38:50<00:00, 17.65s/grupo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de grupos sin datos: 11/132\n",
      "Número de grupos fuera del límite de espera: 0/132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PROCESANDO TMN_CON (TEMPERATURA): 100%|██████████| 132/132 [28:37<00:00, 13.01s/grupo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de grupos sin datos: 23/132\n",
      "Número de grupos fuera del límite de espera: 0/132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PROCESANDO HR_CAL_MX_D (HUM RELATIVA): 100%|██████████| 132/132 [29:53<00:00, 13.59s/grupo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de grupos sin datos: 26/132\n",
      "Número de grupos fuera del límite de espera: 0/132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PROCESANDO HR_CAL_MN_D (HUM RELATIVA): 100%|██████████| 132/132 [29:03<00:00, 13.21s/grupo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de grupos sin datos: 26/132\n",
      "Número de grupos fuera del límite de espera: 0/132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PROCESANDO PTPM_CON (PRECIPITACION): 100%|██████████| 132/132 [1:11:54<00:00, 32.69s/grupo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de grupos sin datos: 3/132\n",
      "Número de grupos fuera del límite de espera: 0/132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Uso funcion get_station_data\n",
    "parametros_etiquetas = {\n",
    "    \"Nivel Máximo\": {\"IdParametro\": \"NIVEL\", \"Etiqueta\": \"NV_MX_D\"},\n",
    "    \"Nivel Mínimo\": {\"IdParametro\": \"NIVEL\", \"Etiqueta\": \"NV_MN_D\"},\n",
    "    \"Nivel Medio\": {\"IdParametro\": \"NIVEL\", \"Etiqueta\": \"NV_MEDIA_D\"},\n",
    "    \"Temperatura Máxima\": {\"IdParametro\": \"TEMPERATURA\", \"Etiqueta\": \"TMX_CON\"},\n",
    "    \"Temperatura Mínima\": {\"IdParametro\": \"TEMPERATURA\", \"Etiqueta\": \"TMN_CON\"},\n",
    "    \"Humedad Relativa Máxima\": {\"IdParametro\": \"HUM RELATIVA\", \"Etiqueta\": \"HR_CAL_MX_D\"},\n",
    "    \"Humedad Relativa Mínima\": {\"IdParametro\": \"HUM RELATIVA\", \"Etiqueta\": \"HR_CAL_MN_D\"},\n",
    "    #\"Nubosidad 7:00 13:00 18:00\": {\"IdParametro\": \"NUBOSIDAD\", \"Etiqueta\": \"NB_CON\"},\n",
    "    \"Precipitación Acumulada\": {\"IdParametro\": \"PRECIPITACION\", \"Etiqueta\": \"PTPM_CON\"}\n",
    "}\n",
    "\n",
    "for nombre_parametro, valores in parametros_etiquetas.items():\n",
    "    try:\n",
    "        get_station_data(\n",
    "            catalogo_estaciones_activas['CODIGO'].tolist(),\n",
    "            '2000-1-1',\n",
    "            '2023-12-31',\n",
    "            valores['IdParametro'],\n",
    "            valores['Etiqueta']\n",
    "        )\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "LCuXTDx0jA4g",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "id": "LCuXTDx0jA4g",
    "outputId": "aa03c3fc-7917-45e5-9230-feade87b074c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-0cec1757-ec36-4fa6-b604-3b769d32c124\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CodigoEstacion</th>\n",
       "      <th>NombreEstacion</th>\n",
       "      <th>Latitud</th>\n",
       "      <th>Longitud</th>\n",
       "      <th>Altitud</th>\n",
       "      <th>Categoria</th>\n",
       "      <th>Entidad</th>\n",
       "      <th>AreaOperativa</th>\n",
       "      <th>Departamento</th>\n",
       "      <th>Municipio</th>\n",
       "      <th>...</th>\n",
       "      <th>FechaSuspension</th>\n",
       "      <th>IdParametro</th>\n",
       "      <th>Etiqueta</th>\n",
       "      <th>DescripcionSerie</th>\n",
       "      <th>Frecuencia</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Valor</th>\n",
       "      <th>Grado</th>\n",
       "      <th>Calificador</th>\n",
       "      <th>NivelAprobacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21115180</td>\n",
       "      <td>HACIENDA MANILA - AUT [21115180]</td>\n",
       "      <td>3.133056</td>\n",
       "      <td>-75.081528</td>\n",
       "      <td>600</td>\n",
       "      <td>Agrometeorológica</td>\n",
       "      <td>INSTITUTO DE HIDROLOGIA METEOROLOGIA Y ESTUDIO...</td>\n",
       "      <td>Area Operativa 04 - Huila-Caquetá</td>\n",
       "      <td>Huila</td>\n",
       "      <td>Baraya</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRECIPITACION</td>\n",
       "      <td>PTPM_CON</td>\n",
       "      <td>Día pluviométrico (convencional)</td>\n",
       "      <td>Diaria</td>\n",
       "      <td>2000-01-03 00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21115180</td>\n",
       "      <td>HACIENDA MANILA - AUT [21115180]</td>\n",
       "      <td>3.133056</td>\n",
       "      <td>-75.081528</td>\n",
       "      <td>600</td>\n",
       "      <td>Agrometeorológica</td>\n",
       "      <td>INSTITUTO DE HIDROLOGIA METEOROLOGIA Y ESTUDIO...</td>\n",
       "      <td>Area Operativa 04 - Huila-Caquetá</td>\n",
       "      <td>Huila</td>\n",
       "      <td>Baraya</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRECIPITACION</td>\n",
       "      <td>PTPM_CON</td>\n",
       "      <td>Día pluviométrico (convencional)</td>\n",
       "      <td>Diaria</td>\n",
       "      <td>2000-01-04 00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21115180</td>\n",
       "      <td>HACIENDA MANILA - AUT [21115180]</td>\n",
       "      <td>3.133056</td>\n",
       "      <td>-75.081528</td>\n",
       "      <td>600</td>\n",
       "      <td>Agrometeorológica</td>\n",
       "      <td>INSTITUTO DE HIDROLOGIA METEOROLOGIA Y ESTUDIO...</td>\n",
       "      <td>Area Operativa 04 - Huila-Caquetá</td>\n",
       "      <td>Huila</td>\n",
       "      <td>Baraya</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRECIPITACION</td>\n",
       "      <td>PTPM_CON</td>\n",
       "      <td>Día pluviométrico (convencional)</td>\n",
       "      <td>Diaria</td>\n",
       "      <td>2000-01-05 00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21115180</td>\n",
       "      <td>HACIENDA MANILA - AUT [21115180]</td>\n",
       "      <td>3.133056</td>\n",
       "      <td>-75.081528</td>\n",
       "      <td>600</td>\n",
       "      <td>Agrometeorológica</td>\n",
       "      <td>INSTITUTO DE HIDROLOGIA METEOROLOGIA Y ESTUDIO...</td>\n",
       "      <td>Area Operativa 04 - Huila-Caquetá</td>\n",
       "      <td>Huila</td>\n",
       "      <td>Baraya</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRECIPITACION</td>\n",
       "      <td>PTPM_CON</td>\n",
       "      <td>Día pluviométrico (convencional)</td>\n",
       "      <td>Diaria</td>\n",
       "      <td>2000-01-06 00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21115180</td>\n",
       "      <td>HACIENDA MANILA - AUT [21115180]</td>\n",
       "      <td>3.133056</td>\n",
       "      <td>-75.081528</td>\n",
       "      <td>600</td>\n",
       "      <td>Agrometeorológica</td>\n",
       "      <td>INSTITUTO DE HIDROLOGIA METEOROLOGIA Y ESTUDIO...</td>\n",
       "      <td>Area Operativa 04 - Huila-Caquetá</td>\n",
       "      <td>Huila</td>\n",
       "      <td>Baraya</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRECIPITACION</td>\n",
       "      <td>PTPM_CON</td>\n",
       "      <td>Día pluviométrico (convencional)</td>\n",
       "      <td>Diaria</td>\n",
       "      <td>2000-01-07 00:00</td>\n",
       "      <td>14.6</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cec1757-ec36-4fa6-b604-3b769d32c124')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-0cec1757-ec36-4fa6-b604-3b769d32c124 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-0cec1757-ec36-4fa6-b604-3b769d32c124');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-8e2de9c4-466d-481f-9035-6de10050836b\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8e2de9c4-466d-481f-9035-6de10050836b')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-8e2de9c4-466d-481f-9035-6de10050836b button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   CodigoEstacion                    NombreEstacion   Latitud   Longitud  \\\n",
       "0        21115180  HACIENDA MANILA - AUT [21115180]  3.133056 -75.081528   \n",
       "1        21115180  HACIENDA MANILA - AUT [21115180]  3.133056 -75.081528   \n",
       "2        21115180  HACIENDA MANILA - AUT [21115180]  3.133056 -75.081528   \n",
       "3        21115180  HACIENDA MANILA - AUT [21115180]  3.133056 -75.081528   \n",
       "4        21115180  HACIENDA MANILA - AUT [21115180]  3.133056 -75.081528   \n",
       "\n",
       "   Altitud          Categoria  \\\n",
       "0      600  Agrometeorológica   \n",
       "1      600  Agrometeorológica   \n",
       "2      600  Agrometeorológica   \n",
       "3      600  Agrometeorológica   \n",
       "4      600  Agrometeorológica   \n",
       "\n",
       "                                             Entidad  \\\n",
       "0  INSTITUTO DE HIDROLOGIA METEOROLOGIA Y ESTUDIO...   \n",
       "1  INSTITUTO DE HIDROLOGIA METEOROLOGIA Y ESTUDIO...   \n",
       "2  INSTITUTO DE HIDROLOGIA METEOROLOGIA Y ESTUDIO...   \n",
       "3  INSTITUTO DE HIDROLOGIA METEOROLOGIA Y ESTUDIO...   \n",
       "4  INSTITUTO DE HIDROLOGIA METEOROLOGIA Y ESTUDIO...   \n",
       "\n",
       "                       AreaOperativa Departamento Municipio  ...  \\\n",
       "0  Area Operativa 04 - Huila-Caquetá        Huila    Baraya  ...   \n",
       "1  Area Operativa 04 - Huila-Caquetá        Huila    Baraya  ...   \n",
       "2  Area Operativa 04 - Huila-Caquetá        Huila    Baraya  ...   \n",
       "3  Area Operativa 04 - Huila-Caquetá        Huila    Baraya  ...   \n",
       "4  Area Operativa 04 - Huila-Caquetá        Huila    Baraya  ...   \n",
       "\n",
       "  FechaSuspension    IdParametro  Etiqueta                  DescripcionSerie  \\\n",
       "0             NaN  PRECIPITACION  PTPM_CON  Día pluviométrico (convencional)   \n",
       "1             NaN  PRECIPITACION  PTPM_CON  Día pluviométrico (convencional)   \n",
       "2             NaN  PRECIPITACION  PTPM_CON  Día pluviométrico (convencional)   \n",
       "3             NaN  PRECIPITACION  PTPM_CON  Día pluviométrico (convencional)   \n",
       "4             NaN  PRECIPITACION  PTPM_CON  Día pluviométrico (convencional)   \n",
       "\n",
       "  Frecuencia             Fecha Valor  Grado  Calificador NivelAprobacion  \n",
       "0     Diaria  2000-01-03 00:00   0.0     50          NaN            1200  \n",
       "1     Diaria  2000-01-04 00:00   0.0     50          NaN            1200  \n",
       "2     Diaria  2000-01-05 00:00   0.0     50          NaN            1200  \n",
       "3     Diaria  2000-01-06 00:00   0.0     50          NaN            1200  \n",
       "4     Diaria  2000-01-07 00:00  14.6     50          NaN            1200  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo dataset variable precipitacion acumulada diaria\n",
    "df = pd.read_csv(os.path.join(DATA_FOLDER, 'variables', 'PTPM_CON.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6zzBdKepjU80",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6zzBdKepjU80",
    "outputId": "3a9b6afe-5775-4aff-c38c-3a45cc0112c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51130 entries, 0 to 51129\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   CodigoEstacion    51130 non-null  int64  \n",
      " 1   NombreEstacion    51130 non-null  object \n",
      " 2   Latitud           51130 non-null  float64\n",
      " 3   Longitud          51130 non-null  float64\n",
      " 4   Altitud           51130 non-null  int64  \n",
      " 5   Categoria         51130 non-null  object \n",
      " 6   Entidad           51130 non-null  object \n",
      " 7   AreaOperativa     51130 non-null  object \n",
      " 8   Departamento      51130 non-null  object \n",
      " 9   Municipio         51130 non-null  object \n",
      " 10  FechaInstalacion  51130 non-null  object \n",
      " 11  FechaSuspension   0 non-null      float64\n",
      " 12  IdParametro       51130 non-null  object \n",
      " 13  Etiqueta          51130 non-null  object \n",
      " 14  DescripcionSerie  51130 non-null  object \n",
      " 15  Frecuencia        51130 non-null  object \n",
      " 16  Fecha             51130 non-null  object \n",
      " 17  Valor             51130 non-null  float64\n",
      " 18  Grado             51130 non-null  int64  \n",
      " 19  Calificador       12 non-null     object \n",
      " 20  NivelAprobacion   51130 non-null  int64  \n",
      "dtypes: float64(4), int64(4), object(13)\n",
      "memory usage: 8.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084b8402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de DataFrames \n",
    "variables_dataframes = {}\n",
    "\n",
    "# Leer cada archivo en la carpeta de datos\n",
    "for archivo in os.listdir(os.path.join(DATA_FOLDER, 'variables')):\n",
    "    if archivo.endswith('.csv'):\n",
    "        # Extraer el nombre del archivo sin extensión\n",
    "        nombre_variable = os.path.splitext(archivo)[0]\n",
    "        \n",
    "        # Leer el archivo CSV y solo cargar las columnas necesarias, especificando los tipos de datos\n",
    "        archivo_path = os.path.join(DATA_FOLDER, 'variables', archivo)\n",
    "\n",
    "        df = pd.read_csv(archivo_path, \n",
    "                            usecols=['CodigoEstacion', 'Fecha', 'Valor'],\n",
    "                            dtype={'CodigoEstacion': 'int', 'Fecha': 'str', 'Valor': 'str'})  \n",
    "         \n",
    "        # Convertir la columna Fecha al tipo datetime forzando errores a NaN\n",
    "        df['Fecha'] =  pd.to_datetime(df['Fecha'], errors='coerce').dt.normalize()  \n",
    "\n",
    "        # Convertir la columna 'Valor' a float32, forzando errores a NaN\n",
    "        df['Valor'] = pd.to_numeric(df['Valor'], errors='coerce').astype('float32')\n",
    "        \n",
    "        # Redondear la columna 'Valor' a 1 decimales\n",
    "        df['Valor'] = df['Valor'].round(1)\n",
    "        \n",
    "        # Renombrar la columna 'Valor' con el nombre de la variable (archivo)\n",
    "        df.rename(columns={'Valor': nombre_variable}, inplace=True)\n",
    "\n",
    "        # Guardar el DataFrame en el diccionario usando el nombre de la variable\n",
    "        variables_dataframes[nombre_variable] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28f31fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y ejecutar el procesamiento en paralelo\n",
    "procesar_estaciones_paralelo(\n",
    "    catalogo_estaciones_activas=catalogo_estaciones_activas,\n",
    "    variables_dataframes=variables_dataframes,\n",
    "    fecha_inicio='2000-01-01',\n",
    "    fecha_fin='2023-12-31',\n",
    "    output_folder= os.path.join(DATA_FOLDER, 'estaciones')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fd0702",
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidar_csv(os.path.join(DATA_FOLDER, 'estaciones'), os.path.join(DATA_FOLDER, 'data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a2c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular \n",
    "def calcular_acumulados(df):\n",
    "    # Asegurar que la columna Fecha está en formato de fecha\n",
    "    df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "    \n",
    "    # Ordenar por CodigoEstacion y Fecha para asegurar el cálculo adecuado\n",
    "    df = df.sort_values(by=['CodigoEstacion', 'Fecha'])\n",
    "    \n",
    "    # Definir los días para los que se calcularán promedios y sumatorias\n",
    "    dias_promedios = [1, 3, 7, 15, 30]\n",
    "    \n",
    "    # Listas de columnas\n",
    "    columnas_promedio = ['PTPM_CON','HR_CAL_MN_D', 'HR_CAL_MX_D', 'NV_MEDIA_D', 'NV_MN_D', 'NV_MX_D', 'TMN_CON', 'TMX_CON']\n",
    "    \n",
    "    # Crear un nuevo DataFrame para almacenar los resultados\n",
    "    df_resultado = df.copy()\n",
    "    \n",
    "    # Calcular promedios móviles para cada estacion\n",
    "    for dias in dias_promedios:\n",
    "        for col in columnas_promedio:\n",
    "            # Crear la columna nueva para el promedio\n",
    "            col_nueva = f'{col}_{dias}D'\n",
    "            # Calcular el promedio\n",
    "            df_resultado[col_nueva] = df.groupby('CodigoEstacion')[col].transform(lambda x: x.shift(1).rolling(window=dias, min_periods=dias).mean())\n",
    "\n",
    "    # Redondear a un decimal\n",
    "    df_resultado = df_resultado.round(2)\n",
    "\n",
    "    # Eliminar filas donde todas las columnas son NaN\n",
    "    df_resultado = df_resultado.dropna(how='all', subset=[f'{col}_{dias}D' for dias in dias_promedios for col in columnas_promedio])\n",
    "\n",
    "    return df_resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "912aba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset\n",
    "df = pd.read_csv(os.path.join(DATA_FOLDER, 'data.csv'))\n",
    "\n",
    "# Calcular los acumulados\n",
    "df_acumulados = calcular_acumulados(df)\n",
    "df_acumulados = df_acumulados.drop(columns=['HR_CAL_MN_D', 'HR_CAL_MX_D', 'NV_MEDIA_D', 'NV_MN_D', 'NV_MX_D', 'TMN_CON', 'TMX_CON'])\n",
    "\n",
    "# Guardar el resultado en un archivo CSV\n",
    "output_path = os.path.join(DATA_FOLDER, 'data_acumulados.csv')\n",
    "df_acumulados.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eb29be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17990978 entries, 0 to 17990977\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Dtype         \n",
      "---  ------          -----         \n",
      " 0   CodigoEstacion  int64         \n",
      " 1   Fecha           datetime64[ns]\n",
      " 2   HR_CAL_MN_D     float64       \n",
      " 3   HR_CAL_MX_D     float64       \n",
      " 4   NV_MEDIA_D      float64       \n",
      " 5   NV_MN_D         float64       \n",
      " 6   NV_MX_D         float64       \n",
      " 7   PTPM_CON        float64       \n",
      " 8   TMN_CON         float64       \n",
      " 9   TMX_CON         float64       \n",
      "dtypes: datetime64[ns](1), float64(8), int64(1)\n",
      "memory usage: 1.3 GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e6cee11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 17988609 entries, 1 to 17743192\n",
      "Data columns (total 43 columns):\n",
      " #   Column           Dtype         \n",
      "---  ------           -----         \n",
      " 0   CodigoEstacion   int64         \n",
      " 1   Fecha            datetime64[ns]\n",
      " 2   PTPM_CON         float64       \n",
      " 3   PTPM_CON_1D      float64       \n",
      " 4   HR_CAL_MN_D_1D   float64       \n",
      " 5   HR_CAL_MX_D_1D   float64       \n",
      " 6   NV_MEDIA_D_1D    float64       \n",
      " 7   NV_MN_D_1D       float64       \n",
      " 8   NV_MX_D_1D       float64       \n",
      " 9   TMN_CON_1D       float64       \n",
      " 10  TMX_CON_1D       float64       \n",
      " 11  PTPM_CON_3D      float64       \n",
      " 12  HR_CAL_MN_D_3D   float64       \n",
      " 13  HR_CAL_MX_D_3D   float64       \n",
      " 14  NV_MEDIA_D_3D    float64       \n",
      " 15  NV_MN_D_3D       float64       \n",
      " 16  NV_MX_D_3D       float64       \n",
      " 17  TMN_CON_3D       float64       \n",
      " 18  TMX_CON_3D       float64       \n",
      " 19  PTPM_CON_7D      float64       \n",
      " 20  HR_CAL_MN_D_7D   float64       \n",
      " 21  HR_CAL_MX_D_7D   float64       \n",
      " 22  NV_MEDIA_D_7D    float64       \n",
      " 23  NV_MN_D_7D       float64       \n",
      " 24  NV_MX_D_7D       float64       \n",
      " 25  TMN_CON_7D       float64       \n",
      " 26  TMX_CON_7D       float64       \n",
      " 27  PTPM_CON_15D     float64       \n",
      " 28  HR_CAL_MN_D_15D  float64       \n",
      " 29  HR_CAL_MX_D_15D  float64       \n",
      " 30  NV_MEDIA_D_15D   float64       \n",
      " 31  NV_MN_D_15D      float64       \n",
      " 32  NV_MX_D_15D      float64       \n",
      " 33  TMN_CON_15D      float64       \n",
      " 34  TMX_CON_15D      float64       \n",
      " 35  PTPM_CON_30D     float64       \n",
      " 36  HR_CAL_MN_D_30D  float64       \n",
      " 37  HR_CAL_MX_D_30D  float64       \n",
      " 38  NV_MEDIA_D_30D   float64       \n",
      " 39  NV_MN_D_30D      float64       \n",
      " 40  NV_MX_D_30D      float64       \n",
      " 41  TMN_CON_30D      float64       \n",
      " 42  TMX_CON_30D      float64       \n",
      "dtypes: datetime64[ns](1), float64(41), int64(1)\n",
      "memory usage: 5.9 GB\n"
     ]
    }
   ],
   "source": [
    "df_acumulados.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698f42d4",
   "metadata": {
    "id": "698f42d4"
   },
   "source": [
    "## **Créditos**\n",
    "\n",
    "* **Profesor:** [Fabio Augusto Gonzalez](https://dis.unal.edu.co/~fgonza/)\n",
    "* **Asistentes docentes :**\n",
    "  * [Santiago Toledo Cortés](https://sites.google.com/unal.edu.co/santiagotoledo-cortes/)\n",
    "* **Diseño de imágenes:**\n",
    "    - [Mario Andres Rodriguez Triana](https://www.linkedin.com/in/mario-andres-rodriguez-triana-394806145/).\n",
    "* **Coordinador de virtualización:**\n",
    "    - [Edder Hernández Forero](https://www.linkedin.com/in/edder-hernandez-forero-28aa8b207/).\n",
    "\n",
    "**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
